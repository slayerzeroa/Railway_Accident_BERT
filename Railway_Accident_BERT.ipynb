{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "IBZ3UXZtjIbA",
        "Js1n6xKKlfxM",
        "Ppm736thjDGk",
        "CvtIIJici-n-"
      ],
      "authorship_tag": "ABX9TyMyZw8qCtB281gF8hku6AyI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slayerzeroa/Railway_Accident_BERT/blob/main/Railway_Accident_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install nltk\n",
        "!pip install pytorch-crf"
      ],
      "metadata": {
        "id": "ogoXI5OM7LcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리\n",
        "import torch\n",
        "from torch import nn, optim, tensor\n",
        "from torch.utils.data import DataLoader, Dataset,TensorDataset, random_split\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "import json\n",
        "import glob\n",
        "import re\n",
        "import os\n",
        "import ast\n",
        "import html\n",
        "\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "RH5K6Y2c2UD6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#디바이스 세팅\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "IJwQl0n9F25R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# google api key\n",
        "key = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "XEIiZO-Yx9iK",
        "outputId": "61e60882-8992-4376-edf7-350c0c2d16b7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-68da65c8-b92f-4238-9c3a-aafff83c97f2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-68da65c8-b92f-4238-9c3a-aafff83c97f2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving railway-tagtog-d24e6901ddb0.json to railway-tagtog-d24e6901ddb0.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sample Annotation : JSON to csv\n",
        "by TAGTOG"
      ],
      "metadata": {
        "id": "sbw_4qrPDWUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "#로그인 위치\n",
        "url = \"https://tagtog.com/-login\"\n",
        "\n",
        "#다운로드 위치\n",
        "file_url = 'https://www.tagtog.com/slayerzeroa/Railway_BERT/-downloads/dataset-as-anndoc' \n",
        "o_file = 'abc.zip'  \n",
        "if os.path.exists(o_file):\n",
        "    os.remove(o_file)\n",
        "\n",
        "#로그인 정보\n",
        "login_info = {\n",
        "    'loginid' : 'slayerzeroa@gmail.com',\n",
        "    'password' : 'gyysxw5rU3NzrYX',\n",
        "}\n",
        "\n",
        "#로그인\n",
        "with requests.Session() as s:\n",
        "    login_req = s.post(url, data=login_info)\n",
        "    r = s.get(file_url)\n",
        "\n",
        "    with open(o_file,\"wb\") as output:\n",
        "        output.write(r.content)"
      ],
      "metadata": {
        "id": "tEpJ0wJbsfa1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#압축파일 풀기\n",
        "import zipfile\n",
        "import shutil\n",
        "folder_path = \"./tagtog_relation_extraction/\"\n",
        "\n",
        "zip_ = zipfile.ZipFile(\"abc.zip\")\n",
        "if os.path.exists(folder_path):\n",
        "    shutil.rmtree(folder_path)\n",
        "zip_.extractall(folder_path)"
      ],
      "metadata": {
        "id": "wvm1sisNsffS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import glob\n",
        "import re\n",
        "import os\n",
        "#폴더 경로\n",
        "folder_name = \"./tagtog_relation_extraction/Railway_BERT/\"\n",
        "\n",
        "#context list\n",
        "context_name_list = os.listdir(folder_name + \"plain.html/pool\")\n",
        "print(context_name_list)\n",
        "\n",
        "#relation 폴더 경로\n",
        "relation_folder_paths = glob.glob(folder_name + \"ann.json/master/pool\")\n",
        "\n",
        "#context 폴더 경로\n",
        "# contexts_folders_paths = glob.glob(folder_name + \"plain.html/pool/*\")\n",
        "contexts_folders_paths = [folder_name + \"plain.html/pool/\" + c for c in context_name_list]\n",
        "\n",
        "print(contexts_folders_paths)\n",
        "\n",
        "#anntation_lenged 정보\n",
        "annotation_legend = folder_name + \"annotations-legend.json\"\n",
        "with open(annotation_legend,\"r\") as f:\n",
        "    annotation_legend = json.load(f)\n",
        "\n",
        "print(annotation_legend)"
      ],
      "metadata": {
        "id": "2VNJGT64sfj_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce8d6f0d-4bb4-4153-ea00-afb08d1faeb0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a3DnzcVSvJKG25OeznRpiW5zLgi8-sample.pdf.plain.html']\n",
            "['./tagtog_relation_extraction/Railway_BERT/plain.html/pool/a3DnzcVSvJKG25OeznRpiW5zLgi8-sample.pdf.plain.html']\n",
            "{'e_23': 'SOLUTION', 'r_19': 'mz4f90xj280(e_6|e_4)', 'r_26': '5zjoi2gg5ps(e_6|e_23)', 'e_22': 'ACCIDENT', 'r_25': '6oyjvcblqfe(e_22|e_23)', 'e_6': 'IMPLIED', 'r_27': 'f19f8drqjkn(e_4|e_23)', 'e_4': 'CAUSE', 'r_24': 'yz4ctet7cda(e_4|e_22)'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#relation dictionary 파일로부터 subject와 object의 entity 정보를 추출해주는 함수\n",
        "def get_needed_relation_data(tmp_relation):\n",
        "    subject_token = re.findall(\"\\(+(.+)+\\)\",annotation_legend[tmp_relation[\"relations\"][0]['classId']])[0].split(\"|\")[0]\n",
        "    if subject_token == tmp_relation['entities'][0]['classId']:\n",
        "        cause, implied = tmp_relation['entities']\n",
        "    else:\n",
        "        implied, cause  = tmp_relation['entities']\n",
        "    \n",
        "    # get preprocessed entities\n",
        "    def _get_entity(entity):\n",
        "        outputs = entity['offsets'][0]\n",
        "        outputs['type'] = annotation_legend[entity['classId']].split(\"-\")[0].lower()\n",
        "        return outputs\n",
        "    \n",
        "    output_cause = _get_entity(cause)\n",
        "    output_implied = _get_entity(implied)\n",
        "    return output_cause, output_implied"
      ],
      "metadata": {
        "id": "_22_zwi3nKno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#relation dictionary 파일로부터 title(relation)을 추출해주는 함수\n",
        "def get_label(relation_json):\n",
        "    label_tag = relation_json['relations'][0]['classId'] #r_6\n",
        "    try:\n",
        "        sub_type, label = annotation_legend[re.findall(\"\\(+(.+)+\\|\",annotation_legend[label_tag])[0]].split(\"-\"), label_tag\n",
        "        return f\"{sub_type}:{label}\"\n",
        "    except:\n",
        "        sub_type, = annotation_legend[re.findall(\"\\(+(.+)+\\|\",annotation_legend[label_tag])[0]].split(\"-\")\n",
        "        return f\"{sub_type}:no_relation\""
      ],
      "metadata": {
        "id": "nTlxq-0jnL0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#html 파일로부터 text만 추출해주는 함수\n",
        "def get_context_from_html(html_file):\n",
        "    html_file = re.sub('(<([^>]+)>)', '', html_file)\n",
        "    return html_file"
      ],
      "metadata": {
        "id": "-G02esnhnOAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#entity 정보가 포함된 sentence를 생성해주는 함수\n",
        "def get_sentence_with_entites(subject_entity, object_entity, sentence):\n",
        "    if subject_entity['start'] < object_entity['start']:\n",
        "        entity1,entity2 = subject_entity, object_entity\n",
        "    else:\n",
        "        entity1,entity2 = object_entity, subject_entity\n",
        "    \n",
        "    #entity 시작 위치 및 길이 \n",
        "    ett1_stt, ett1_len = entity1['start'], len(entity1['text'])\n",
        "    ett2_stt, ett2_len = entity2['start'], len(entity2['text'])\n",
        "    \n",
        "    #문장 분리\n",
        "    bf, ett1, mid, ett2, af = sentence[:ett1_stt], \\\n",
        "                            sentence[ett1_stt:ett1_stt+ett1_len], \\\n",
        "                            sentence[ett1_stt+ett1_len:ett2_stt], \\\n",
        "                            sentence[ett2_stt:ett2_stt+ett2_len], \\\n",
        "                            sentence[ett2_stt+ett2_len:]\n",
        "\n",
        "    \n",
        "    if subject_entity['start'] < object_entity['start']:\n",
        "        ett1,ett2 = f\"<sbj:{ett1}>\", f\"<obj:{ett2}>\"\n",
        "    else:\n",
        "        ett1,ett2 = f\"<obj:{ett1}>\", f\"<sbj:{ett2}>\"\n",
        "    \n",
        "    return \"\".join([bf, ett1, mid, ett2, af])"
      ],
      "metadata": {
        "id": "DmOMMJ0jnQNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataframe column\n",
        "# id : context title(e.g : 카카오게임, 11번가 등)\n",
        "# sentence w/o entity\n",
        "# sentence w entity\n",
        "# subject_entity\n",
        "# object_entity\n",
        "# class\n",
        "\n",
        "id_list = []\n",
        "sentence_list = []\n",
        "sentence_with_entities_list = []\n",
        "subject_entity_list = []\n",
        "object_entity_list = []\n",
        "relation_list = []\n",
        "# tagtog 데이터를 CSV 형태로 변경\n",
        "for context_name, relation_folder, contexts_folder in zip(context_name_list, relation_folder_paths, contexts_folders_paths):\n",
        "    # relation files와 context files 리스트 출력\n",
        "    file_ids = [file_name for file_name in os.listdir(relation_folder)]\n",
        "    file_nums = [ids.split(\"-\")[1] for ids in file_ids]\n",
        "    relation_files = [relation_folder + \"/\"+ file_id for file_id in file_ids]\n",
        "    context_files = [contexts_folder for file_id in file_ids]\n",
        "\n",
        "    #json으로 된 relation data와 html로 된 context 데이터 읽기\n",
        "    for relation_file, context_file, file_num in zip(relation_files,context_files, file_nums):\n",
        "        #subject, object 정보 추출\n",
        "        with open(relation_file, \"r\") as f:\n",
        "            relation_json = json.load(f)\n",
        "            tmp_subject, tmp_object = get_needed_relation_data(relation_json) #subject, object\n",
        "            tmp_label = get_label(relation_json)\n",
        "        try:\n",
        "            tmp_subject, tmp_object = get_needed_relation_data(relation_json) #subject, object\n",
        "            tmp_label = get_label(relation_json)\n",
        "        except:\n",
        "            continue\n",
        "        #sentence, sentence with entities 정보 추출\n",
        "        with open(context_file, \"r\") as f:\n",
        "            context_json = f.read()\n",
        "        tmp_sentence = get_context_from_html(context_json)\n",
        "        tmp_sentence_w_entities = get_sentence_with_entites(tmp_subject,tmp_object,tmp_sentence)\n",
        "        \n",
        "        #각 list에 데이터 저장\n",
        "        id_list.append(f\"{context_name}_{file_num}\")\n",
        "        sentence_list.append(tmp_sentence)\n",
        "        sentence_with_entities_list.append(tmp_sentence_w_entities)\n",
        "        subject_entity_list.append(tmp_subject)\n",
        "        object_entity_list.append(tmp_object)\n",
        "        relation_list.append(tmp_label.lower())"
      ],
      "metadata": {
        "id": "MVB1BCtBnWRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(subject_entity_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW8gLRzYrOoz",
        "outputId": "af4a6fbb-1904-45df-cf21-e258b6a514d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'start': 3704, 'text': '화차에 컨테이너를 싣고 내릴 때 차축 베어링에 충격이 가해진 것', 'type': 'implied'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 참고 자료 : \n",
        "\n",
        "# !pip install gspread\n",
        "# !pip install oauth2client\n",
        "\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "\n",
        "scope = ['https://spreadsheets.google.com/feeds',\n",
        "         'https://www.googleapis.com/auth/drive']\n",
        "\n",
        "#json key file 위치\n",
        "json_file_name = './railway-tagtog-d24e6901ddb0.json'\n",
        "\n",
        "# json key file을 이용하여 접속\n",
        "credentials = ServiceAccountCredentials.from_json_keyfile_name(json_file_name, scope)\n",
        "gc = gspread.authorize(credentials)\n",
        "\n",
        "#구글 스프레드 시트 주소\n",
        "spreadsheet_url = \"https://docs.google.com/spreadsheets/d/1cpt2ad2pw0N2tC1H3MPtRAaZzFmgCh2If0gHOQKEIIo/edit#gid=0\"\n",
        "\n",
        "# 스프레드시트 문서 가져오기\n",
        "doc = gc.open_by_url(spreadsheet_url)\n",
        "## gc.create(spreadsheet_name) # 스프레드시트 생성\n",
        "\n",
        "\n",
        "#시트 선택하기\n",
        "sheet_name = \"annotation\"\n",
        "worksheet = doc.worksheet(sheet_name) #해당 시트가 있는 경우 불러오기\n",
        "## 403 error가 뜰 경우, google sheets API를 활성시켜줘야 함"
      ],
      "metadata": {
        "id": "PveqSBqVndUn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시트의 모든 데이터 가져오기\n",
        "values = worksheet.get_all_values()\n",
        "header, rows = values[0], values[1:]\n",
        "data = pd.DataFrame(rows, columns=header)\n",
        "column_list = [\"id\",\"sentence\",\"sentence_with_entity\",\"subject_entity\",\"object_entity\",\"class\"]\n",
        "data = data[column_list]\n",
        "data.head()\n",
        "\n",
        "sen_list =  list(data.sentence_with_entity.values)\n",
        "len(sen_list)\n",
        "\n",
        "worksheet.resize(len(id_list)+1,10)\n",
        "list_range = f\"a2:f{len(id_list)+1}\"\n",
        "cell_list = worksheet.range(list_range)\n",
        "\n",
        "for i in range(len(cell_list)//len(column_list)):\n",
        "    cell_list[(6*i)].value = id_list[i]\n",
        "    cell_list[(6*i)+1].value = sentence_list[i]\n",
        "    cell_list[(6*i)+2].value = sentence_with_entities_list[i]\n",
        "    cell_list[(6*i)+3].value = str(subject_entity_list[i])\n",
        "    cell_list[(6*i)+4].value = str(object_entity_list[i])\n",
        "    cell_list[(6*i)+5].value = relation_list[i]\n",
        "worksheet.update_cells(cell_list)"
      ],
      "metadata": {
        "id": "pCIE2LCqnduR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbeb1b83-9a00-46bc-bf72-18d43c14ed92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1cpt2ad2pw0N2tC1H3MPtRAaZzFmgCh2If0gHOQKEIIo',\n",
              " 'updatedRange': 'annotation!A2:F2',\n",
              " 'updatedRows': 1,\n",
              " 'updatedColumns': 6,\n",
              " 'updatedCells': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenizer Pre-Trained"
      ],
      "metadata": {
        "id": "IBZ3UXZtjIbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
      ],
      "metadata": {
        "id": "tEgwHtcdMOmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizing_(token_list, label_list, tokenizer):\n",
        "  text_seq = []\n",
        "  valid_seq = []\n",
        "  label_seq = label_list\n",
        "  for tokens, label in zip(token_list, label_list):\n",
        "    new_target_text = []\n",
        "    new_valid = []\n",
        "    for i, (t, l) in enumerate(zip(tokens, label)):\n",
        "      tokens_wordpiece = tokenizer.tokenize(t)\n",
        "      new_v = [1] + [0]*(len(tokens_wordpiece)-1)\n",
        "      new_target_text.extend(tokens_wordpiece)\n",
        "      new_valid.extend(new_v)\n",
        "    valid_seq.append(new_valid)\n",
        "    text_seq.append(new_target_text)\n",
        "  return text_seq, valid_seq, label_seq"
      ],
      "metadata": {
        "id": "iz4LXOrQoATP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_seq, valid_seq, label_seq = tokenizing_(token_list, label_list, tokenizer)"
      ],
      "metadata": {
        "id": "KUaZwhsOLqW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_seq)\n",
        "print(valid_seq)\n",
        "print(label_seq)"
      ],
      "metadata": {
        "id": "_lTQt5FnMbz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizing_rel(token_list, label_list, rel_list, tokenizer):\n",
        "  text_seq = []\n",
        "  valid_seq = []\n",
        "  final_left_seq = []\n",
        "  final_right_seq = []\n",
        "  label_seq = []\n",
        "\n",
        "  for tokens, label, rel in zip(token_list, label_list, rel_list):\n",
        "    lefts, rights, labels = rel\n",
        "\n",
        "    for le, ri, la in zip(lefts, rights, labels):\n",
        "      new_target_text = []\n",
        "      new_valid = []\n",
        "      new_left = []\n",
        "      new_right = []\n",
        "      before_label = -1\n",
        "\n",
        "      for i, (t, l) in enumerate(zip(tokens, label)):\n",
        "        tokens_wordpiece = tokenizer.tokenize(t)\n",
        "        if before_label != l and l != -1:\n",
        "          if l == le:\n",
        "            tokens_wordpiece = [\"*\"] + tokens_wordpiece\n",
        "          elif l == ri:\n",
        "            tokens_wordpiece = [\"#\"] + tokens_wordpiece\n",
        "        \n",
        "        if l != -1 and i+1 != len(label) and l != label[i+1]:\n",
        "          if l == le:\n",
        "            tokens_wordpiece = tokens_wordpiece + [\"*\"]\n",
        "          elif l == ri:\n",
        "            tokens_wordpiece = tokens_wordpiece + [\"#\"]\n",
        "        \n",
        "        if l != -1 and i+1 == len(label):\n",
        "          if l == le:\n",
        "            tokens_wordpiece = tokens_wordpiece + [\"*\"]\n",
        "          elif l == ri:\n",
        "            tokens_wordpiece = tokens_wordpiece + [\"#\"]\n",
        "        \n",
        "        before_label = l\n",
        "        new_v = [l]*(len(tokens_wordpiece))\n",
        "        new_target_text.extend(tokens_wordpiece)\n",
        "        new_valid.extend(new_v)\n",
        "      \n",
        "      leftaa = [float(x == le) for x in new_valid]\n",
        "      rightaa = [float(x == ri) for x in new_valid]\n",
        "      final_left_seq.append(leftaa)\n",
        "      final_right_seq.append(rightaa)\n",
        "      text_seq.append(new_target_text)\n",
        "      label_seq.append(la)\n",
        "    return text_seq, final_left_seq, final_right_seq, label_seq"
      ],
      "metadata": {
        "id": "mFHJ9gXGqzku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_greedy_label(rel_list, dic_rel_label, max_labels):\n",
        "  final_rel_list = []\n",
        "\n",
        "  for rel, max_lab in zip(rel_list, max_labels):\n",
        "    temp_les = []\n",
        "    temp_re =[]\n",
        "    rel_labels = rel[4]\n",
        "    rel_lefts = rel[5]\n",
        "    rel_rights = rel[6]\n",
        "    max_value = max_lab\n",
        "    l, r = make_fair_by_max(max_value)\n",
        "    new_l = []\n",
        "    new_r = []\n",
        "    qomax = len(rel_labels)\n",
        "    z = 0\n",
        "\n",
        "    for ll, rr in zip(l, r):\n",
        "      q = 0\n",
        "      laba = 0\n",
        "      for lf, ri, rel_label in zip(rel_lefts, rel_rights, rel_labels):\n",
        "        if ll == lf and rr == ri:\n",
        "          q = 1\n",
        "          laba = dic_rel_label[rel_label]\n",
        "      \n",
        "      if q == 1:\n",
        "        new_l.append(ll)\n",
        "        new_r.append(rr)\n",
        "        temp_les.append(laba)\n",
        "      elif z < 1.5*qomax:\n",
        "        new_l.append(ll)\n",
        "        new_r.append(rr)\n",
        "        z = z + 1\n",
        "        temp_les.append(0)\n",
        "      \n",
        "    final_rel_list.append((new_l, new_r, temp_les))\n",
        "  return final_rel_list"
      ],
      "metadata": {
        "id": "BpvnNH0Ku9P_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Relation BERT"
      ],
      "metadata": {
        "id": "1P37vclkjQU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "RxK1Mj3IveBf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset = pd.DataFrame(worksheet.get_all_values()).iloc[1:-1]\n",
        "# column = pd.DataFrame(worksheet.get_all_values()).iloc[:1]\n",
        "# Dataset.columns = column.values[0]\n",
        "\n",
        "# print(Dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtKNqxxmuOS8",
        "outputId": "082e1048-5972-42e2-b4d7-bf5fbc3ac0a7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Doc          Loc       Cls       Part  \\\n",
            "1  sample    3704_3607   e_6_e_4  s1p5_s1p5   \n",
            "2  sample    3741_3607   e_6_e_4  s1p5_s1p5   \n",
            "3  sample  13057_12960   e_6_e_4  s1p6_s1p6   \n",
            "4  sample  13094_12960   e_6_e_4  s1p6_s1p6   \n",
            "5  sample    3394_3607  e_22_e_4  s1p5_s1p5   \n",
            "6  sample    3434_3607  e_22_e_4  s1p5_s1p5   \n",
            "7  sample    3455_3607  e_22_e_4  s1p5_s1p5   \n",
            "8  sample  13368_13094  e_23_e_6  s1p6_s1p6   \n",
            "\n",
            "                                                 Sub  \\\n",
            "1                화차에 컨테이너를 싣고 내릴 때 차축 베어링에 충격이 가해진 것   \n",
            "2  차축 베어링의 분해검수 주기와 교환 주기가 화차에 적재되는 화 물의 종류, 적재방법...   \n",
            "3                화차에 컨테이너를 싣고 내릴 때 차축 베어링에 충격이 가해진 것   \n",
            "4  차축 베어링의 분해검수 주기와 교환 주기가 화차에 적재되는 화 물의 종류, 적재방법...   \n",
            "5                뒷 대차 첫 번째 차축과 두 번째 차축이 진행방향 좌측으로 탈선   \n",
            "6                                    좌 측 세 번째 차축이 절손   \n",
            "7                    탈선화차와 14번째 화차 사이의 공기호스 가 빠져있는 것   \n",
            "8  화차 차축 베어링의 분해검수 주기와 교환 주기를 화차에 적재되는 화 물의 종류, 적...   \n",
            "\n",
            "                                                 Obj Label  \n",
            "1  차축에 설치되어 있는 차축 베어링 외륜의 내면과 롤러에 결함이 있는 상태에서 운행 ...     1  \n",
            "2  차축에 설치되어 있는 차축 베어링 외륜의 내면과 롤러에 결함이 있는 상태에서 운행 ...     1  \n",
            "3  차축에 설치되어 있는 차축 베어링 외륜의 내면과 롤러에 결함이 있는 상태에서 운행 ...     1  \n",
            "4  차축에 설치되어 있는 차축 베어링 외륜의 내면과 롤러에 결함이 있는 상태에서 운행 ...     1  \n",
            "5  차축에 설치되어 있는 차축 베어링 외륜의 내면과 롤러에 결함이 있는 상태에서 운행 ...     1  \n",
            "6  차축에 설치되어 있는 차축 베어링 외륜의 내면과 롤러에 결함이 있는 상태에서 운행 ...     1  \n",
            "7  차축에 설치되어 있는 차축 베어링 외륜의 내면과 롤러에 결함이 있는 상태에서 운행 ...     1  \n",
            "8  차축 베어링의 분해검수 주기와 교환 주기가 화차에 적재되는 화 물의 종류, 적재방법...     1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_mlm = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "_ldnSoX90orQ",
        "outputId": "0eae4334-6d07-4152-de1c-08b030b3f035"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b36525bd-16ac-456f-835d-6ed79def3e33\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b36525bd-16ac-456f-835d-6ed79def3e33\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving MLM_1.json to MLM_1.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLMTrainDataset_Sik(Dataset):\n",
        "  \n",
        "  def __init__(self, max_len, mask_prob, mask_token, sep_token, cls_token, all_sents,\n",
        "               tokenizer, pad_token):\n",
        "    self.all_sents = all_sents\n",
        "    self.num_vocabs = tokenizer.vocab_size\n",
        "    self.max_len = max_len\n",
        "    self.mask_prob = mask_prob\n",
        "    self.mask_token = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(mask_token))\n",
        "    self.cls_token = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(cls_token))\n",
        "    self.sep_token = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sep_token))\n",
        "    self.tokenizer = tokenizer\n",
        "    self.pad_token = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(pad_token))\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.all_sents)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    sents = self.all_sents[index]\n",
        "    sents = self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(sents))\n",
        "    tokens = []\n",
        "    sents = np.array(sents)\n",
        "    inputs = sents\n",
        "    labels = inputs.copy()\n",
        "\n",
        "    probability_matrix = torch.full(labels.shape, self.mask_prob)\n",
        "\n",
        "    masked_indices = torch.bernoulli(probability_matrix).bool()\n",
        "    \n",
        "    labels[~masked_indices] = -100\n",
        "\n",
        "    indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
        "\n",
        "    inputs[indices_replaced] = self.tokenzier.convert_tokens_to_ids(self.mask_token)\n",
        "\n",
        "    indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
        "\n",
        "    random_words = torch.randint(len(self.tokenizer), labels.shape, dtype = torch.long)\n",
        "\n",
        "    inputs[indices_random] = random_words[indices_random]\n",
        "    inputs = list(inputs)\n",
        "    labels = list(labels)\n",
        "    valid_length = min(len(inputs), self.max_len-2)\n",
        "    tokens = self.cls_token + inputs[:self.max_len-2] + self.sep_token\n",
        "    labels = [-100] + labels[:self.max_len-2] + [-100]\n",
        "\n",
        "    mask_len = self.max_len - len(tokens)\n",
        "\n",
        "    tokens = tokens + self.pad_token * mask_len\n",
        "    labels = labels + [-100] * mask_len\n",
        "    attention_masks = [0.0]*len(tokens)\n",
        "    for i in range(valid_length):\n",
        "      attention_masks[i] = 1.0\n",
        "    \n",
        "    return torch.LongTensor(tokens), torch.LongTensor(labels), valid_length, torch.LongTensor(attention_masks)"
      ],
      "metadata": {
        "id": "9vfwORZvwL9I"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_mlm = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "8rwflSss4AYb",
        "outputId": "e3811a67-f265-4263-e97f-6b2783c3da27"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-37046588-c204-4866-96d1-4d2e09f1899d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-37046588-c204-4866-96d1-4d2e09f1899d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sample.plain.html to sample.plain.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing = test_mlm.decode('utf-8')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "brJ0W5iD4IZS",
        "outputId": "1c95a35f-bc7c-4b36-be62-a92365acb3b6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-ea8a608fa07c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtesting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'decode'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sep_token=\"[SEP]\"\n",
        "pad_token=\"[PAD]\"\n",
        "cls_token=\"[CLS]\"\n",
        "mask_token=\"[MASK]\"\n",
        "max_len = 60\n",
        "mask_prob = 0.15\n",
        "\n",
        "\n",
        "test_instance = MLMTrainDataset_Sik(max_len, mask_prob, mask_token, sep_token, cls_token, test_mlm, BertTokenizer, pad_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "pHn9s_CHuIn5",
        "outputId": "2779d8b2-53ec-4927-ce8f-85b3572e8d80"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-001e84d743b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtest_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLMTrainDataset_Sik\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mlm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-f4d39c4c4e18>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, max_len, mask_prob, mask_token, sep_token, cls_token, all_sents, tokenizer, pad_token)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msep_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: tokenize() missing 1 required positional argument: 'text'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchcrf import CRF\n",
        "\n",
        "# 개체명 인식 모델 Class 코드\n",
        "class Bert_entity(nn.Module):\n",
        "  def __init__(self, model, num_labels):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "    self.hidden_size = 768\n",
        "    self.block_size = 64\n",
        "    self.hidden_layer = nn.Linear(768, 768)\n",
        "    self.classifier = nn.Linear(768, num_labels)\n",
        "    self.dropout = nn.Dropout(0.4)\n",
        "    self.num_labels = num_labels\n",
        "    self.crf = CRF(num_tags = num_labels, batch_first=True)\n",
        "  \n",
        "  def forward(self,\n",
        "              input_ids = None,\n",
        "              attention_mask = None,\n",
        "              labels = None,\n",
        "              valid_ids = None,\n",
        "              label_mask = None):\n",
        "    \n",
        "    output = self.model(input_ids = input_ids, attention_mask = attention_mask)\n",
        "    last_hidden_state = output.last_hidden_state\n",
        "    valid_output = torch.zeros(last_hidden_state.size()[0], last_hidden_state.size()[1],\n",
        "                               last_hidden_state.size()[2], dtype=torch.float32, device='cuda:1')\n",
        "    valid_masks = torch.zeros(last_hidden_state.size()[0], last_hidden_state.size()[1],\n",
        "                              dtype=torch.bool, device='cuda:1')\n",
        "    \n",
        "    for i in range(last_hidden_state.size()[0]):\n",
        "      jj = -1\n",
        "      for j in range(last_hidden_state.size()[1]):\n",
        "        if valid_ids[i][j].item() == 1:\n",
        "          jj += 1\n",
        "          valid_masks[i][jj] = 1\n",
        "          valid_output[i][jj] = last_hidden_state[i][j]\n",
        "      \n",
        "      relations = self.dropout(valid_output)\n",
        "      logits = self.classifier(relations)\n",
        "      loss = None\n",
        "      if labels is not None:\n",
        "        if attention_mask is not None:\n",
        "          loss, logits = self.crf(logits, labels, mask = valid_masks, reduction = 'token_mean'), self.crf.decode(logits, mask=valid_masks)\n",
        "        else:\n",
        "          loss, logits = self.crf(logits, labels, mask = valid_masks, reduction = 'token_mean'), self.crf.decode(logits, mask=valid_masks)\n",
        "      return -loss, logits, last_hidden_state, valid_output, output.attentions\n"
      ],
      "metadata": {
        "id": "fJpEt0Mb2kJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 개체간 관계 추출 모델 Class 코드\n",
        "class Bert_relation(nn.Module):\n",
        "  def __init__(self, model, num_labels):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "    self.hidden_size =768\n",
        "    self.block_size = 64\n",
        "\n",
        "    self.head_extractor = nn.Linear(768, 768)\n",
        "    self.tail_extractor = nn.Linear(768, 768)\n",
        "\n",
        "    self.bilinear_classifier = nn.Linear(768 * 3, num_labels)\n",
        "\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "    self.num_labels = num_labels\n",
        "  \n",
        "  def get_hrts(self, valid_output, left_ids, right_ids):\n",
        "    left_masks = left_ids.unsqueeze(-1).expand(valid_output.size()).float()\n",
        "    right_masks = right_ids.unsqueeze(-1).expand(valid_output.size()).float()\n",
        "\n",
        "    left_rep = torch.logsumexp(valid_output * left_masks, dim=1)\n",
        "    right_rep = torch.logsumexp(valid_output * right_masks, dim=1)\n",
        "\n",
        "    return left_rep, right_rep\n",
        "  \n",
        "  def forward(self,\n",
        "              input_ids=None,\n",
        "              attention_mask=None,\n",
        "              labels=None,\n",
        "              valid_ids=None,\n",
        "              label_mask=None,\n",
        "              left_ids=None,\n",
        "              right_ids=None):\n",
        "    output = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    last_hidden_state = output.last_hidden_state\n",
        "    pooled_output = output.pooler_output\n",
        "    context = self.dropout(pooled_output)\n",
        "    valid_output = last_hidden_state\n",
        "\n",
        "    left_rep, right_rep = self.get_hrts(valid_output, left_ids, right_ids)\n",
        "\n",
        "    left_rep = self.head_extractor(left_rep)\n",
        "    right_rep = self.head_extractor(right_rep)\n",
        "\n",
        "    bl = torch.cat([context, left_rep, right_rep], dim=-1)\n",
        "\n",
        "    logits = self.bilinear_classifier(bl)\n",
        "    loss = None\n",
        "\n",
        "    if labels is None:\n",
        "      loss_fct = torch.nn.BCEWithLogitsLoss()\n",
        "      loss = loss_fct(logits, labels.float())\n",
        "\n",
        "    output = logits\n",
        "\n",
        "    return loss, output if loss is not None else output"
      ],
      "metadata": {
        "id": "d1RycRmj8Qfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_most_similar_words(word, total_words):\n",
        "  q = []\n",
        "\n",
        "  for a in total_words:\n",
        "    k = jaccard_similarity(word, a[0])\n",
        "    q.append((a, k))\n",
        "  q.sort(key=lambda x:x[1])\n",
        "  qq = q[-20:]\n",
        "  new_q = []\n",
        "  for qa in qq:\n",
        "    if qa[1] > 0.05:\n",
        "      new_q.append(qa)\n",
        "  \n",
        "  return new_q"
      ],
      "metadata": {
        "id": "hdVMwKQhJgFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard_similarity(word1, word2):\n",
        "  word1 = word1.lower()\n",
        "  word2 = word2.lower()\n",
        "  trigram1 = trigram_from_word(word1)\n",
        "  trigram2 = trigram_from_word(word2)\n",
        "\n",
        "  set_trigram = set(trigram1)\n",
        "  set_trigram = set_trigram.union(set(trigram2))\n",
        "  con_trigram = [t in trigram2 for t in trigram1]\n",
        "  qq = sum(con_trigram)\n",
        "  la = 0.0\n",
        "  la = float(float(qq)/float(len(set_trigram)+1e-9))\n",
        "\n",
        "  return la"
      ],
      "metadata": {
        "id": "SfeWOBqwQkq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trigram_from_word(word):\n",
        "  if len(word) < 3:\n",
        "    return [word]\n",
        "  \n",
        "  else:\n",
        "    trigram = [word[i:i+3] for i in range(len(word)-3)]\n",
        "    return trigram"
      ],
      "metadata": {
        "id": "4Hxea9nARNYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sample : PDF to TXT"
      ],
      "metadata": {
        "id": "Js1n6xKKlfxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "!pip install pdfminer.six"
      ],
      "metadata": {
        "id": "A8oWUsXKlkHd",
        "cellView": "code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import pdfminer\n",
        "from pdfminer.high_level import extract_text\n",
        "from google.colab import files\n",
        "\n",
        "pdf = files.upload()"
      ],
      "metadata": {
        "id": "ldJUFR7npkkC",
        "cellView": "code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(pdf)"
      ],
      "metadata": {
        "id": "HwL0cPhrpsOh",
        "cellView": "code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "file_path = \"sample.pdf\"\n",
        "\n",
        "text = extract_text(pdf_file=file_path)\n"
      ],
      "metadata": {
        "id": "PNxzYfKbp0GA",
        "cellView": "code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "from io import StringIO\n",
        "\n",
        "from pdfminer.converter import TextConverter\n",
        "from pdfminer.layout import LAParams\n",
        "from pdfminer.pdfdocument import PDFDocument\n",
        "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
        "from pdfminer.pdfpage import PDFPage\n",
        "from pdfminer.pdfparser import PDFParser\n",
        "\n",
        "output_string = StringIO()\n",
        "with open(file_path, 'rb') as in_file:\n",
        "    parser = PDFParser(in_file)\n",
        "    doc = PDFDocument(parser)\n",
        "    rsrcmgr = PDFResourceManager()\n",
        "    device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
        "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
        "    for page in PDFPage.create_pages(doc):\n",
        "        interpreter.process_page(page)\n",
        "\n",
        "print(output_string.getvalue())"
      ],
      "metadata": {
        "id": "AKYgFGUVq4R-",
        "cellView": "code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenizing"
      ],
      "metadata": {
        "id": "Ppm736thjDGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "str = output_string.getvalue()\n",
        "new_str = re.sub(\"\\n\", \"\", str)\n",
        "new_str = re.sub(\"·\", \"\", new_str)\n",
        "\n",
        "print(new_str)"
      ],
      "metadata": {
        "id": "YSdmiVZD5kKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "BlCkotjt-g6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "word_tokens = word_tokenize(new_str)\n",
        "sent_tokens = sent_tokenize(new_str)\n",
        "\n",
        "print(sent_tokens)"
      ],
      "metadata": {
        "id": "Ea49FUcJ-NEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "id": "e8H2nVuq5w1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install collections"
      ],
      "metadata": {
        "id": "RVFpSvysAN4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "from collections import Counter\n",
        "okt = Okt()\n",
        "noun = okt.nouns(text)\n",
        "for i, v in enumerate(noun):\n",
        "  if len(v) < 2:\n",
        "    noun.pop(i)\n",
        "\n",
        "count = Counter(noun)"
      ],
      "metadata": {
        "id": "Uik8A28t87PB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 빈도 카운트\n",
        "noun_list = count.most_common(100)\n",
        "for v in noun_list:\n",
        "  print(v)"
      ],
      "metadata": {
        "id": "wduRrIYk9lKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BERT Training"
      ],
      "metadata": {
        "id": "CvtIIJici-n-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-multilingual-cased')"
      ],
      "metadata": {
        "id": "1LfjYJn-DnMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = bert_tokenizer(text, return_tensors='pt')\n",
        "print(inputs)"
      ],
      "metadata": {
        "id": "bus7ncLBD98B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs['labels'] = inputs.input_ids.detach().clone()"
      ],
      "metadata": {
        "id": "RVnFUnA9GtTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand = torch.rand(inputs.input_ids.shape)\n",
        "\n",
        "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * (inputs.input_ids != 102) # 101, 102번 토큰 제외하고 15% 위치 선별\n",
        "\n",
        "### padding이 포함된 경우(0번도 추가 제외) ###\n",
        "# mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * (inputs.input_ids != 102) * (inputs.input_ids != 0)\n",
        "\n",
        "selection = torch.flatten((mask_arr[0]).nonzero())"
      ],
      "metadata": {
        "id": "ogURvy6ZG8HZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "selection_val = np.random.random(len(selection)) # selection의 위치마다 0~1 값 부여\n",
        "\n",
        "mask_selection = selection[np.where(selection_val >= 0.2)[0]] # 80% : Mask 토큰 대체\n",
        "random_selection = selection[np.where(selection_val < 0.1)[0]] # 10% : 랜덤 토큰 대체\n",
        "\n",
        "print(random_selection) # tensor([ 30,  95, 143])\n",
        "print(mask_selection)"
      ],
      "metadata": {
        "id": "rCvxrEcVG-gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.input_ids[0, mask_selection] = 103\n",
        "inputs.input_ids[0, random_selection] = torch.randint(0, 30522, size = random_selection.shape)\n",
        "\n",
        "print(inputs)"
      ],
      "metadata": {
        "id": "nXDL2jAjHOPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**inputs)"
      ],
      "metadata": {
        "id": "EArKkfn3HQP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")"
      ],
      "metadata": {
        "id": "1FTgrbxVHR2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = tokenizer.tokenize(new_str)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "rvHyzuzzyrxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CS3N5T_nzyZb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}